<body>
    <div id="gameDiv">
    </div>
</body>
<canvas id="meter" width="500" height="50"></canvas>
<script src="client/lib/phaser.min.js"></script>
<script src="/socket.io/socket.io.js"></script>
<script src="https://webrtc.github.io/adapter/adapter-latest.js"></script>


<script src="client/volume.js"></script>
<script src="client/gyro.min.js"></script>
<button onclick="startup()">Initialize</button>
<script>
    var audioContext = null;
    var meter = null;
    var canvasContext = document.getElementById("meter").getContext("2d");
    var WIDTH = 500;
    var HEIGHT = 50;
    var rafID = null;
    var Storage = {};
    var AudioContext = window.AudioContext || window.webkitAudioContext;

    function startup() {
        console.log("go fuq urself");


        //        if ("vibrate" in window.navigator) {
        //            window.navigator.vibrate(100);
        //        }


        // grab our canvas
        // canvasContext = document.getElementById("meter").getContext("2d");

        // monkeypatch Web Audio


        // grab an audio context
        //audioContext = new AudioContext();

        // Attempt to get audio input
        //        try {
        //            // monkeypatch getUserMedia
        //            navigator.getUserMedia =
        //                (navigator.getUserMedia ||
        //                    navigator.webkitGetUserMedia ||
        //                    navigator.mozGetUserMedia ||
        //                    navigator.msGetUserMedia);
        //
        //            // ask for an audio input
        //            navigator.getUserMedia({
        //                "audio": true
        //            }, onMicrophoneGranted, onMicrophoneDenied);
        //        } catch (e) {
        //            alert(e);
        //        }
        setupStorage();

        navigator.mediaDevices.getUserMedia({
                audio: true
            })
            .then(onMicrophoneGranted)
            .catch(onMicrophoneDenied);

    }

    function onMicrophoneDenied() {
        console.log("There was an error accessing the microphone. You may need to allow the browser access");
    }

    var mediaStreamSource = null;

    function onMicrophoneGranted(stream) {
        console.log("i am crey");
        // Create an AudioNode from the stream.
        mediaStreamSource = Storage.ctx.createMediaStreamSource(stream);

        // Create a new volume meter and connect it.
        meter = createAudioMeter(Storage.ctx);
        mediaStreamSource.connect(meter);

        // kick off the visual updating
        onLevelChange();
    }

    function setupStorage() {
        console.log("take 2 action");
        //audioContext = new AudioContext();
        Storage.ctx = new AudioContext();
        //audioContext = Storage.ctx;
        //window.AudioContext = window.AudioContext || window.webkitAudioContext;
    }

    function onLevelChange(time) {
        // clear the background
        canvasContext.clearRect(0, 0, WIDTH, HEIGHT);

        // check if we're currently clipping
        if (meter.checkClipping()) {
            //window.navigator.vibrate([1000, 2000, 1000]);
            canvasContext.fillStyle = "red";
        } else
            canvasContext.fillStyle = "green";

        console.log(meter.volume);
        if (meter.volume >= 0.001) {
            window.navigator.vibrate([1000, 2000, 1000]);
            console.log("hmm");
        }

        // draw a bar based on the current volume
        canvasContext.fillRect(0, 0, meter.volume * WIDTH * 1.4, HEIGHT);

        // set up the next visual callback
        rafID = window.requestAnimationFrame(onLevelChange);
    }


    //    window.onload = function() {
    //
    //    }

</script>
